---
title: "Assignment2"
author: "jesper fischer ehmsen"
date: "2023-02-23"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(cmdstanr)
library(ggtext)
library(posterior)
library(bayesplot)
library(ggdist)
library(brms)




#tester


source("~/Advanced-cognitive-modeling/agents.R")
source("~/Advanced-cognitive-modeling/stan_helpers.R")
```


## R Markdown


```{r}

#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 120
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l = 0
#alpha1_l is the learning rate for the first agent (matcher) when winning
alpha1_w = 0
#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l = 0
#alpha1_l is the learning rate for the first agent (non-matcher) when winning
alpha2_w = 0
#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1 = 0.2
#bias 2 is what bias1 is for agent2
bias2 = 0.2

#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0


#different agents:
#random bias:
#to initialize a random bias agent the learning rates for that agent just have to set to 0 and the bias is will then determine the bias of the agent:

#win stay lose shift (WSLS):
#to initialize a (WSLS) agent the two learning rates for the agent has to be set to 1.

#rescorla wagner(RW) learner with constant learning rate
#to initialize this RW agent the two learning rates for the agent just have to be equal

#rescorla wagner(RW) learner with different learning rate for wins and loses
#to initialize a RW agent the two learning rates for the agent just have to be different:



#make the agents play once (not included)
df = rw_vs_rw(ntrials = ntrials,
         alpha1_l = alpha1_l,
         alpha1_w = alpha1_w,
         alpha2_l = alpha2_l,
         alpha2_w = alpha2_w,
         bias1 = bias1,
         bias2 = bias2,
         incentive1 = incentive1,  # 0 doesn't care about ,  1 does the oppisite
         incentive2 = incentive2
         )

df = data.frame(df)


#lets fit in stan:

setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/bias_vs_bias.stan"

mod = cmdstan_model(filemodel)

datap = list(rw1 = df$rw1, rw2 = df$rw2, n = nrow(df), prior = 1)
data = list(rw1 = df$rw1, rw2 = df$rw2, n = nrow(df), prior = 0)


prior <- mod$sample(
  data = datap, 
  seed = 123,
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

fit <- mod$sample(
  data = data, 
  seed = 123,
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

prior = as_draws_df(prior$draws())
prior$prior = 1

draws = as_draws_df(fit$draws())
draws$prior = 0

draws2 = rbind(draws,prior)


draws2 %>% pivot_longer(cols = c("theta1_prior","theta2_prior")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))




draws %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value))+facet_wrap(~name)+
  geom_histogram(alpha = 0.8, fill = "darkblue", binwidth = 1, col = "black")+
  geom_histogram(data = prior %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)),aes(x = value),alpha = 0.3, fill = "red", binwidth = 1, col = "black")+xlab(paste("choosing '1' on ",ntrials," trials"))+ylab("posterior density")+
  geom_point(data = df %>% summarize(rw1 = sum(rw1)) %>% mutate(name = "sim_rw1"), aes(x = rw1, y = 0), col = "green",size = 6, shape = 17)+
  geom_point(data = df %>% summarize(rw2 = sum(rw2)) %>% mutate(name = "sim_rw2"), aes(x = rw2, y = 0), col = "green",size = 6, shape = 17)
  


```



```{r}
#priors are normal (0, 2), as the above plot (comes from bias_vs_bias)
#parameter recovery

pr = parameter_recovery_bias_vs_bias(ngames = 20,
                                     trials = 20)

pr$plot
```



```{r}
#sensitivity analysis:
ngamess = 5

sens_mean = sensitivty_bias_vs_bias(ngames = ngamess,
                               trials = 15,
                               mean = seq(-3,3,length.out = ngamess))

sens_mean$plot


sens_sd = sensitivty_bias_vs_bias(ngames = ngamess,
                                  trials = 15,
                                  sd = seq(0.1,1,length.out = ngamess))
sens_sd$plot
```






```{r}
#rw vs Rescorla wagner fit one participant
source("~/Advanced-cognitive-modeling/agents.R")

#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 120
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l = 0.8
#alpha1_l is the learning rate for the first agent (matcher) when winning
alpha1_w = 0.8
#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l = 0.1
#alpha1_l is the learning rate for the first agent (non-matcher) when winning
alpha2_w = 0.1
#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1 = 0.5
#bias 2 is what bias1 is for agent2
bias2 = 0.5

#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0


#different agents:
#random bias:
#to initialize a random bias agent the learning rates for that agent just have to set to 0 and the bias is will then determine the bias of the agent:

#win stay lose shift (WSLS):
#to initialize a (WSLS) agent the two learning rates for the agent has to be set to 1.

#rescorla wagner(RW) learner with constant learning rate
#to initialize this RW agent the two learning rates for the agent just have to be equal

#rescorla wagner(RW) learner with different learning rate for wins and loses
#to initialize a RW agent the two learning rates for the agent just have to be different:



#make the agents play once (not included)
df = rw_vs_rw(ntrials = ntrials,
         alpha1_l = alpha1_l,
         alpha1_w = alpha1_w,
         alpha2_l = alpha2_l,
         alpha2_w = alpha2_w,
         bias1 = bias1,
         bias2 = bias2,
         incentive1 = incentive1,  # 0 doesn't care about ,  1 does the oppisite
         incentive2 = incentive2
         )

df = data.frame(df)


#lets fit in stan:

setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/rw_vs_rw.stan"

mod = cmdstan_model(filemodel)

data = list(rw1 = df$rw1, rw2 = df$rw2, fb_rw1 = df$feedback_rw1, fb_rw2 = df$feedback_rw2, n = nrow(df), prior = 0)
datap = list(rw1 = df$rw1, rw2 = df$rw2, fb_rw1 = df$feedback_rw1, fb_rw2 = df$feedback_rw2, n = nrow(df), prior = 1)

fit <- mod$sample(
  data = data, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

prior <- mod$sample(
  data = datap, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)





prior = as_draws_df(prior$draws(c("theta1_prior", "theta2_prior","alpha1_prior","alpha2_prior","sim_rw1","sim_rw2")))
prior$prior = 1

draws = as_draws_df(fit$draws(c("theta1_prior", "theta2_prior","alpha1_prior","alpha2_prior","sim_rw1","sim_rw2")))
draws$prior = 0

draws2 = rbind(draws,prior)


draws2 %>% pivot_longer(cols = c("theta1_prior","theta2_prior")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))

draws2 %>% pivot_longer(cols = c("alpha1_prior","alpha2_prior")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))



draws %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value))+facet_wrap(~name)+
  geom_histogram(alpha = 0.8, fill = "darkblue", binwidth = 1, col = "black")+
  geom_histogram(data = prior %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)),aes(x = value),alpha = 0.3, fill = "red", binwidth = 1, col = "black")+xlab(paste("choosing '1' on ",ntrials," trials"))+ylab("posterior density")+
  geom_point(data = df %>% summarize(rw1 = sum(rw1)) %>% mutate(name = "sim_rw1"), aes(x = rw1, y = 0), col = "green",size = 6, shape = 17)+
  geom_point(data = df %>% summarize(rw2 = sum(rw2)) %>% mutate(name = "sim_rw2"), aes(x = rw2, y = 0), col = "green",size = 6, shape = 17)


```


```{r}
#parameter recovery of rescorla wagner vs rescorla wagner

#prios = 
source("~/Advanced-cognitive-modeling/stan_helpers.R")
library(ggdist)
#parameter recovery
pr = parameter_recovery_rw_vs_rw(ngames = 5,
                                 trials = 20,
                                 lr1 = 0.3,
                                 lr2 = 0.7)

pr$plot
```



```{r}
#differing learning rates for winning and losing:

#Rw vs RW
source("~/Advanced-cognitive-modeling/agents.R")

#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 500
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l = 0.8
#alpha1_l is the learning rate for the first agent (matcher) when winning
alpha1_w = 0.6
#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l = 0.6
#alpha1_l is the learning rate for the first agent (non-matcher) when winning
alpha2_w = 0.3
#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1 = 0.5
#bias 2 is what bias1 is for agent2
bias2 = 0.5

#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0


#different agents:
#random bias:
#to initialize a random bias agent the learning rates for that agent just have to set to 0 and the bias is will then determine the bias of the agent:

#win stay lose shift (WSLS):
#to initialize a (WSLS) agent the two learning rates for the agent has to be set to 1.

#rescorla wagner(RW) learner with constant learning rate
#to initialize this RW agent the two learning rates for the agent just have to be equal

#rescorla wagner(RW) learner with different learning rate for wins and loses
#to initialize a RW agent the two learning rates for the agent just have to be different:



#make the agents play once (not included)
df = rw_vs_rw(ntrials = ntrials,
         alpha1_l = alpha1_l,
         alpha1_w = alpha1_w,
         alpha2_l = alpha2_l,
         alpha2_w = alpha2_w,
         bias1 = bias1,
         bias2 = bias2,
         incentive1 = incentive1,  # 0 doesn't care about ,  1 does the oppisite
         incentive2 = incentive2
         )

df = data.frame(df)

#lets fit in stan:

setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/rw_win_lose_vs_rw.stan"

mod = cmdstan_model(filemodel)

data = list(rw1 = df$rw1, rw2 = df$rw2, fb_rw1 = df$feedback_rw1, fb_rw2 = df$feedback_rw2, n = nrow(df), prior = 0)
datap = list(rw1 = df$rw1, rw2 = df$rw2, fb_rw1 = df$feedback_rw1, fb_rw2 = df$feedback_rw2, n = nrow(df), prior = 1)


fit <- mod$sample(
  data = data, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)



prior <- mod$sample(
  data = datap, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)







prior = as_draws_df(prior$draws(c("theta1_prior", "theta2_prior","alpha1l_prior","alpha1w_prior","alpha2l_prior","alpha2w_prior","sim_rw1","sim_rw2")))
prior$prior = 1

draws = as_draws_df(fit$draws(c("theta1_prior", "theta2_prior","alpha1l_prior","alpha1w_prior","alpha2l_prior","alpha2w_prior","sim_rw1","sim_rw2")))
draws$prior = 0

draws2 = rbind(draws,prior)


draws2 %>% pivot_longer(cols = c("theta1_prior","theta2_prior")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))

draws2 %>% pivot_longer(cols = c("alpha1l_prior","alpha2l_prior","alpha1w_prior","alpha2w_prior")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+
  geom_vline(data = data.frame(name  = c("alpha1l_prior","alpha2l_prior","alpha1w_prior","alpha2w_prior"), vals = c(alpha1_l, alpha2_l,alpha1_w,alpha2_w)),aes(xintercept = vals))+
  geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))+theme_classic()



draws %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value))+facet_wrap(~name)+
  geom_histogram(alpha = 0.8, fill = "darkblue", binwidth = 1, col = "black")+
  geom_histogram(data = prior %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)),aes(x = value),alpha = 0.3, fill = "red", binwidth = 1, col = "black")+xlab(paste("choosing '1' on ",ntrials," trials"))+ylab("posterior density")+
  geom_point(data = df %>% summarize(rw1 = sum(rw1)) %>% mutate(name = "sim_rw1"), aes(x = rw1, y = 0), col = "green",size = 6, shape = 17)+
  geom_point(data = df %>% summarize(rw2 = sum(rw2)) %>% mutate(name = "sim_rw2"), aes(x = rw2, y = 0), col = "green",size = 6, shape = 17)





```


```{r}
#pr for that:


#prior:
#N(0,1) for all see   hist(inv_logit_scaled(rnorm(10000,0,1)))
source("~/Advanced-cognitive-modeling/stan_helpers.R")
source("~/Advanced-cognitive-modeling/agents.R")

pr = parameter_recovery_rw_gen(ngames = 5,
                               start_trials = 75, 
                               end_trials = 125, 
                               lr1_l = 0.3, 
                               lr1_w = 0.8,
                               lr2_l = 0.9,
                               lr2_w = 0.1)
pr$plot

```


```{r}
#sensitivity analysis:

source("~/Advanced-cognitive-modeling/stan_helpers.R")
source("~/Advanced-cognitive-modeling/agents.R")

ngamess = 5
sens_mean = sensitivty_recovery_rw_gen(ngames = ngamess,
                               start_trials = 120,
                               end_trials = 122,
                               lr1_l = 0.3, 
                               lr1_w = 0.8,
                               lr2_l = 0.9,
                               lr2_w = 0.1,
                               mean = seq(-3,3,length.out = ngamess))

sens_mean$plot


sens_sd = sensitivty_recovery_rw_gen(ngames = ngamess,
                               start_trials = 120,
                               end_trials = 122,
                               lr1_l = 0.3, 
                               lr1_w = 0.8,
                               lr2_l = 0.9,
                               lr2_w = 0.1,
                               sd = seq(0.1,1,length.out = ngamess))
sens_sd$plot


```





```{r}

#multilevel_model first see that simulation work
#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 120
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l_mu = 0.5
alpha1_l_sd = 0.1

alpha1_w_mu = 0.01
alpha1_w_sd = 0.1


#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l_mu = 0.4
alpha2_l_sd = 0.1



alpha2_w_mu = 0.4
alpha2_w_sd = 0.1



#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1_mu = 0.2
bias1_sd = 0.1

#bias 2 is what bias1 is for agent2
bias2_mu = 0.8
bias2_sd = 0.1


#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0

#make the agents play 100 times and plot it (included)
subjects = 5
source("~/Advanced-cognitive-modeling/agents.R")

agg = rw_vs_rw_hier(subjects = subjects,
         ntrials = ntrials,
         alpha1_l_mu,
         alpha1_l_sd,
         alpha1_w_mu,
         alpha1_w_sd,
         alpha2_l_mu,
         alpha2_l_sd,
         alpha2_w_mu,
         alpha2_w_sd,
         bias1_mu, 
         bias2_mu,
         bias1_sd, 
         bias2_sd,
         incentive1, 
         incentive2)

pairwise = agg$pairlevel
trialevel = agg$triallevel



trialevel$pair = as.factor(trialevel$pair)
trialevel$rw1 = as.factor(trialevel$rw1)

pairwise$pair = as.factor(pairwise$pair)
#plot them:
trialevel %>% mutate(x = rep(1:120,20)) %>% 
  pivot_longer(cols = c("expectation1","expectation2")) %>% inner_join(pairwise, by = "pair") %>% 
  ggplot() +
  geom_line(aes(x = x, y = value, col = name))+
  geom_richtext(aes(x = 30, y = 0, label = paste("alpha1 = ", round(alpha1_l,2))), size = 3)+
  geom_richtext(aes(x = 90, y = 0, label = paste("alpha2 = ", round(alpha2_l,2))), size = 3)+
  facet_wrap(~pair)+
  theme_classic()


```


```{r, dont run}


#then we fit stan model first simply bias vs bais:

source("~/Advanced-cognitive-modeling/agents.R")


#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 120
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l_mu = 0
alpha1_l_sd = 0.01

alpha1_w_mu = 0
alpha1_w_sd = 0.01


#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l_mu = 0
alpha2_l_sd = 0.01



alpha2_w_mu = 0
alpha2_w_sd = 0.01

#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1_mu = 0.2
bias1_sd = 0.01

#bias 2 is what bias1 is for agent2
bias2_mu = 0.8
bias2_sd = 0.01



#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0

#make the agents play 100 times and plot it (included)
subjects = 20



agg = rw_vs_rw_hier(subjects = subjects,
         ntrials = ntrials,
         alpha1_l_mu,
         alpha1_l_sd,
         alpha1_w_mu,
         alpha1_w_sd,
         alpha2_l_mu,
         alpha2_l_sd,
         alpha2_w_mu,
         alpha2_w_sd,
         bias1_mu, 
         bias2_mu,
         bias1_sd, 
         bias2_sd,
         incentive1, 
         incentive2)

pairwise = agg$pairlevel
trialevel = agg$triallevel

data = list(rw1 = as.matrix(agg$rw1), rw2 = as.matrix(agg$rw2), fb_rw1 = as.matrix(agg$rw1_fb), fb_rw2 = as.matrix(agg$rw2_fb), trials = nrow(agg$rw1), subjects = ncol(agg$rw1), prior = 0)







setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/bias_vs_bias_hier.stan"

mod = cmdstan_model(filemodel)


fit <- mod$sample(
  data = data, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)




fit$summary()

mcmc_hist(fit$draws("bias_1_mu"))
mcmc_hist(fit$draws("bias_2_mu"))
mcmc_hist(fit$draws("bias_1_sd"))
mcmc_hist(fit$draws("bias_2_sd"))


```



```{r}
#then we fit stan model first simply bias vs bais:

source("~/Advanced-cognitive-modeling/agents.R")


#different parameter settings for the game and agents:
#ntrials the number of times the agents play the game
ntrials = 120
#alpha1_l is the learning rate for the first agent (matcher) when losing
alpha1_l_mu = 0
alpha1_l_sd = 0.01

alpha1_w_mu = 0
alpha1_w_sd = 0.01


#alpha2_l is the learning rate for the first agent (non-matcher) when losing
alpha2_l_mu = 0
alpha2_l_sd = 0.01



alpha2_w_mu = 0
alpha2_w_sd = 0.01

#bias1 is the bias of the first participant to answer 1. That is if it is 1 then agent 1 will choose 1 on the first trial, if 0.5 he picks at random
bias1_mu = 0.2
bias1_sd = 0.05

#bias 2 is what bias1 is for agent2
bias2_mu = 0.9
bias2_sd = 0.05


#the incentive of the first agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive1 = 0
#the incentive of the second agent do you play after your belief (0) or do you choose the oppisite of your belief (1)
incentive2 = 0

#make the agents play 100 times and plot it (included)
subjects = 10



agg = rw_vs_rw_hier(subjects = subjects,
         ntrials = ntrials,
         alpha1_l_mu,
         alpha1_l_sd,
         alpha1_w_mu,
         alpha1_w_sd,
         alpha2_l_mu,
         alpha2_l_sd,
         alpha2_w_mu,
         alpha2_w_sd,
         bias1_mu,
         bias1_sd,
         bias2_mu,
         bias2_sd,
         incentive1, 
         incentive2)

pairwise = agg$pairlevel
trialevel = agg$triallevel


trialevel$pair = as.factor(trialevel$pair)
trialevel$rw1 = as.factor(trialevel$rw1)

pairwise$pair = as.factor(pairwise$pair)
#plot them:
trialevel %>% mutate(x = rep(1:120,subjects)) %>% 
  pivot_longer(cols = c("expectation1","expectation2")) %>% inner_join(pairwise, by = "pair") %>% 
  ggplot() +
  geom_line(aes(x = x, y = value, col = name))+
  geom_richtext(aes(x = 30, y = 0, label = if(alpha1_l[1] != 0){paste("alpha1_l = ", round(alpha1_l,2))}else{paste("bias1 =", round(bias1,2))}), size = 3)+
  geom_richtext(aes(x = 90, y = 0, label = if(alpha2_l[1] != 0){paste("alpha2_l = ", round(alpha2_l,2))}else{paste("bias2 =", round(bias2,2))}), size = 3)+
  facet_wrap(~pair)+
  theme_classic()

data = list(rw1 = as.matrix(agg$rw1), 
            rw2 = as.matrix(agg$rw2), 
            fb_rw1 = as.matrix(agg$rw1_fb), 
            fb_rw2 = as.matrix(agg$rw2_fb), 
            trials = nrow(agg$rw1), 
            subjects = ncol(agg$rw1),
            prior = 0)


datap = list(rw1 = as.matrix(agg$rw1), 
            rw2 = as.matrix(agg$rw2), 
            fb_rw1 = as.matrix(agg$rw1_fb), 
            fb_rw2 = as.matrix(agg$rw2_fb), 
            trials = nrow(agg$rw1), 
            subjects = ncol(agg$rw1),
            prior = 1)



setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/bias_vs_bias_hier.stan"

mod = cmdstan_model(filemodel)


fit <- mod$sample(
  data = data, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)



prior <- mod$sample(
  data = datap, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)
```




```{r, plot it}

prior = as_draws_df(prior$draws())
prior$prior = 1

draws = as_draws_df(fit$draws())
draws$prior = 0

draws2 = rbind(draws,prior)

#population effects:

draws2 %>% pivot_longer(cols = c("theta1_prior_p","theta2_prior_p")) %>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value, fill = prior))+geom_density(aes(x = value), alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))+
  geom_vline(data = data.frame(name = c("theta1_prior_p","theta2_prior_p"), vals = c(bias1_mu, bias2_mu)), aes(xintercept = vals))


qq = draws2 %>% filter(prior == 0) %>% select(c(starts_with("theta1_prior["))) %>% pivot_longer(cols = everything()) %>% mutate(agent = as.factor(1)) %>% mutate(name = substr(name, 14, 14))
qq1 = draws2%>% filter(prior == 0) %>% select(c(starts_with("theta2_prior["))) %>% pivot_longer(cols = everything()) %>% mutate(agent = as.factor(2)) %>% mutate(name = substr(name, 14, 14))

qq2 = rbind(qq,qq1)

qq2 %>% ggplot(aes(x = value, fill = agent))+
  geom_density(alpha = 0.3)+facet_wrap(~name)+scale_fill_manual(values = c("blue","red"))+
  theme_classic()+
  geom_vline(data = data.frame(name  = rep(1:subjects,2), vals = c(pairwise$bias1,pairwise$bias2), col = as.factor(c(rep(1,subjects),rep(2,subjects)))),aes(xintercept = vals, col = col))+
  scale_color_manual(values = c("blue","red"))





draws %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)) %>% ggplot(aes(x = value))+facet_wrap(~name)+
  geom_histogram(alpha = 0.8, fill = "darkblue", binwidth = 1, col = "black")+
  geom_histogram(data = prior %>% pivot_longer(cols = c("sim_rw1","sim_rw2"))%>% mutate(prior = as.factor(prior)),aes(x = value),alpha = 0.3, fill = "red", binwidth = 1, col = "black")+xlab(paste("choosing '1' on ",ntrials," trials"))+ylab("posterior density")+
  geom_point(data = df %>% summarize(rw1 = sum(rw1)) %>% mutate(name = "sim_rw1"), aes(x = rw1, y = 0), col = "green",size = 6, shape = 17)+
  geom_point(data = df %>% summarize(rw2 = sum(rw2)) %>% mutate(name = "sim_rw2"), aes(x = rw2, y = 0), col = "green",size = 6, shape = 17)



#mcmc_hist(fit$draws("alpha_1_mu"))
#mcmc_hist(fit$draws("alpha_1_sd"))
#mcmc_hist(fit$draws("alpha_2_mu"))
#mcmc_hist(fit$draws("alpha_2_sd"))



mcmc_hist(fit$draws("theta1_prior_p"))
mcmc_hist(fit$draws("theta2_prior_p"))

#mcmc_hist(fit$draws("alpha_1"))
#mcmc_hist(fit$draws("alpha_2"))


mcmc_hist(fit$draws("theta1_prior"))
mcmc_hist(fit$draws("theta2_prior"))

pairwise
```





```{r}
#fitting the hgf to a random bias agent

source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(0.5,rep(c(0.2,0.8),3),0.5)
trials = c(75,rep(c(20,30),3),75)

u = rm_agent(bias,trials)

input = data.frame(kappa = 1.4, theta = 0.3, omega = -2,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4)
data = hgf_agent(u,input)


plothgfdata = function(data){
  q1 = data %>% dplyr::select(u,trial,mu1hat,sa1hat,mu2,sa2,mu3,sa3) %>% mutate(level = 1, mu2 = NA, sa2 = NA,mu3 = NA,sa3 = NA)
  q2 = data %>% dplyr::select(u,trial,mu1hat,sa1hat,mu2,sa2,mu3,sa3) %>% mutate(level = 2, mu1hat = NA, sa1hat = NA, mu3 = NA, sa3 = NA, u = NA)
  q3 = data %>% dplyr::select(u,trial,mu1hat,sa1hat,mu2,sa2,mu3,sa3) %>% mutate(level = 3, mu1hat = NA, sa1hat = NA,mu2 = NA, sa2 = NA, u = NA)
  
  q3 = rbind(q1,q2,q3)
  
  q3$level = as.factor(q3$level)
  
  
  q3 %>% mutate(level = factor(level, labels = c("Predictions","Expectations","Volatility")),level = factor(level, levels = c("Volatility", "Expectations","Predictions")),lower1 = mu1hat-sa1hat, upper1 = mu1hat+sa1hat, lower2 = mu2-sa2, upper2 = mu2+sa2, lower3 = mu3-sa3, upper3 = mu3+sa3) %>%
  ggplot(aes())+
  geom_line(data = data.frame(level = as.factor("Predictions"), x = 1:length(u), y = rep(bias,trials)),aes(x = 1:length(u), y = rep(bias,trials)))+
  facet_wrap(~level, scales = "free",nrow = 3)+
  geom_line(aes(x = trial, y = mu1hat), col = "#c44e52")+
  geom_point(aes(x = trial, y = u), col = "black")+
  geom_ribbon(aes(x = trial, ymax = upper1, ymin = lower1), fill = "#4c72b0", alpha = 0.5)+
  geom_ribbon(aes(x = trial, ymax = upper2, ymin = lower2), fill  = "#c44e52", alpha = 0.5)+
  #geom_ribbon(aes(x = trial, ymax = upper3, ymin = lower3), fill  = "black", alpha = 0.5)+
  geom_line(aes(x = trial, y = mu2), col = "#c44e52")+
  geom_line(aes(x = trial, y = mu3), col = "black")+
  theme_classic()+
  theme(text = element_text(size=12))+
  ylab(" ")
}

```




```{r}
#inverting the HGF

source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(0.5,rep(c(0.2,0.8,0.3,0.9),3),0.5)
trials = c(50,rep(c(20,30,20,20),3),50)

u = rm_agent(bias,trials)

input = data.frame(kappa = 1, theta = 1, omega = -3,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4)
dataq = hgf_agent(u,input)[-1,]

plothgfdata(dataq)


setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/3-level-hgf-no_pu.stan"

mod = cmdstan_model(filemodel)

data1 = list(ntrials = nrow(dataq), u = dataq$u, y = dataq$y)


fit <- mod$sample(
  data = data1, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

library(tidybayes)
library(cmdstanr)
library(brms)

posterior = as_draws_df(fit$draws())
  

qq = posterior %>% tidybayes::gather_draws(mu1hat[trials], sa1hat[trials], mu1[trials], sa2[trials], mu2[trials], mu3[trials], sa3[trials]) %>% 
  group_by(trials, .variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean) %>% filter(trials != nrow(.))
qq$trials = NA
qq$trial = 1:nrow(qq)
qq$y = dataq$y
qq$u = dataq$u


qq1 = posterior %>% tidybayes::gather_draws(theta,omega,kappa) %>% 
  group_by(.variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean)


plot_hgf_perceptual_uncertainty_fitted(qq,qq1)


plot_prior_post_update_nopu(fit,
                       real = input,
                       levels = 3)

```

```{r}
#diagnostics:


```


```{r, fig.height=7}
library(patchwork)
#inverting the HGF

source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(0.5,rep(c(0.2,0.8,0.3,0.9)),0.5)
trials = c(25,rep(c(20,30,20,20)),25)

#bias = c(0.3,0.7)
#trials = c(20,20)


u = rm_agent(bias,trials)

input = data.frame(kappa = 1, theta = 0.2, omega = -2,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4,alpha = 0.2, etaa = 0.9, etab = 0.1)


data = hgf_agent_per_un(u,input)
plot_hgf_perceptual_uncertainty(data)


#plothgfdata(data)


setwd("~/Advanced-cognitive-modeling")
filemodel = "full_hgf.stan"

mod = cmdstan_model(filemodel)

dataq = data[-1,]

data1 = list(ntrials = nrow(dataq), u = dataq$u, y = dataq$y)


fit <- mod$sample(
  data = data1, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)


library(tidybayes)

qq = fit$summary(c("omega","alpha","kappa","theta","etaa","etab"))

posterior = as_draws_df(fit$draws())

#trial by trial estimates
qq = posterior %>% gather_draws(mu1hat[trials], sa1hat[trials], mu1[trials], sa2[trials], mu2[trials], mu3[trials], sa3[trials]) %>% 
  group_by(trials, .variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean) %>% filter(trials != nrow(.))
qq$trials = NA
qq$trial = 1:nrow(qq)
qq$y = dataq$y
qq$u = dataq$u


qq1 = posterior %>% gather_draws(theta,alpha,omega,kappa,etaa,etab) %>% 
  group_by(.variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean)


plot_hgf_perceptual_uncertainty_fitted(qq,qq1)
plot_prior_post_update(fit,
                       real = input,
                       levels = 3)

```

```{r, fig.height=7}
library(patchwork)
#inverting the HGF

source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(0.5,rep(c(0.2,0.8,0.3,0.9)),0.5)
trials = c(25,rep(c(20,30,20,20)),25)

#bias = c(0.3,0.7)
#trials = c(20,20)


u = rm_agent(bias,trials)

input = data.frame(kappa = 0, theta = 0.5, omega = -2,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4,alpha = 0.2, etaa = 0.9, etab = 0.1)


data = hgf_agent_per_un(u,input)
plot_hgf_perceptual_uncertainty(data)


#plothgfdata(data)


setwd("~/Advanced-cognitive-modeling")
filemodel = "2_level_full_hgf.stan"

mod = cmdstan_model(filemodel)

dataq = data[-1,]

data1 = list(ntrials = nrow(dataq), u = dataq$u, y = dataq$y)


fit <- mod$sample(
  data = data1, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)


library(tidybayes)


posterior = as_draws_df(fit$draws())

#trial by trial estimates
qq = posterior %>% gather_draws(mu1hat[trials], sa1hat[trials], mu1[trials], sa2[trials], mu2[trials], mu3[trials], sa3[trials]) %>% 
  group_by(trials, .variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean) %>% filter(trials != nrow(.))
qq$trials = NA
qq$trial = 1:nrow(qq)
qq$y = dataq$y
qq$u = dataq$u


qq1 = posterior %>% gather_draws(theta,alpha,omega,kappa,etaa,etab) %>% 
  group_by(.variable) %>% 
  summarize(mean = mean(.value)) %>% 
  pivot_wider(names_from = .variable,values_from = mean)


plot_hgf_perceptual_uncertainty_fitted(qq,qq1)
plot_prior_post_update(fit,
                       real = input,
                       levels = 2)

```







```{r}
#diagnostics:
draws_df <- as_draws_df(fit$draws())

ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()

draws_df %>% pivot_longer(cols = c("theta","p_theta")) %>% ggplot(aes(x = value,fill = name))+geom_histogram()+theme_classic()+facet_wrap(~name)

draws_df %>% pivot_longer(cols = c("kappa","p_kappa")) %>% ggplot(aes(x = value,fill = name))+geom_histogram()+theme_classic()+facet_wrap(~name)

draws_df %>% pivot_longer(cols = c("omega","p_omega")) %>% ggplot(aes(x = value,fill = name))+geom_histogram()+theme_classic()+facet_wrap(~name)



```











```{r}
library(bayesplot)

dd = as_draws_df(fit$draws(c("theta","omega","p_theta","p_omega","kappa","p_kappa")))
#bayesplot::mcmc_trace(dd)

dd %>% select(theta,omega,p_theta,p_omega,kappa, p_kappa) %>% pivot_longer(cols = everything()) %>% ggplot(aes(x = value, fill = name))+geom_histogram()+theme_classic()+facet_wrap(~name, scales = "free_x")

```



```{r}
#2 level or kalman filter:


source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(0.5,rep(c(0.2,0.8,0.3,0.9),3),0.5)
trials = c(75,rep(c(40,30,40,40),3),75)

u = rm_agent(bias,trials)

input = data.frame(kappa = 0, theta = -3, omega = -4,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4)
data = hgf_agent(u,input)[-1,]

plothgfdata(data)


setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/2HGF.stan"

mod = cmdstan_model(filemodel)

data1 = list(ntrials = nrow(data), u = data$u, y = data$y)


fit <- mod$sample(
  data = data1, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

dd = as_draws_df(fit$draws(c("omega","p_omega")))
library(bayesplot)
bayesplot::mcmc_trace(dd)
summary(dd$omega)

dd %>% select(omega,p_omega) %>% pivot_longer(cols = everything()) %>% ggplot(aes(x = value, fill = name))+geom_histogram()+theme_classic()


```



```{r}


source("/home/jespere/Advanced-cognitive-modeling/assignment2/hgf_agent.R")

bias = c(rep(c(0.2,0.8,0.3,0.9),6), 0.1)
trials = c(rep(c(20,20,20,10),6), 10)

u = rm_agent(bias,trials)

input = data.frame(kappa = 0, theta = -3, omega = -2,Inital_prec2 = 4,Inital_mu2 = 0,Inital_mu3 = 0,Inital_prec3 = 4)
data = hgf_agent(u,input)[-1,]

plothgfdata(data)


setwd("~/Advanced-cognitive-modeling/assignment2")
filemodel = "stan_models/2HGF.stan"

mod = cmdstan_model(filemodel)

data1 = list(ntrials = nrow(data), u = data$u, y = data$y)


fit <- mod$sample(
  data = data1, 
  seed = 123, 
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)


dd = as_draws_df(fit$draws(c("omega","p_omega")))
library(bayesplot)
bayesplot::mcmc_trace(dd)
summary(dd$omega)

dd %>% select(omega,p_omega) %>% pivot_longer(cols = everything()) %>% ggplot(aes(x = value, fill = name))+geom_histogram()+theme_classic()+geom_vline(xintercept = -2)



```

